{
  "sub_issues": [
    {
      "id": "T1",
      "title": "SUB: Decompose SettingsTab.tsx into Sub-Components (Category: Modularity)",
      "body": "**Why (quantified):**\n- Current file size: 1,711 lines (target: ≤500 LOC per file)\n- Contains 5 distinct sub-tabs with unrelated concerns\n- Violates Single Responsibility Principle\n- Difficult to test in isolation (requires mocking entire component)\n- High cognitive load for developers (avg. 15+ min to locate feature)\n- File: `src/components/SettingsTab.tsx`\n\n**Baseline:**\n- Lines of Code: 1,711\n- Cyclomatic Complexity: ~35 (target: ≤10 per function)\n- Test Coverage: Partial (sub-tabs not independently testable)\n- Maintainability Index: LOW\n\n**Plan (small, reversible):**\n- [ ] Step 1: Create `src/components/settings/` directory structure\n- [ ] Step 2: Extract ApiKeysTab component (lines 200-400) → `src/components/settings/ApiKeysTab.tsx` (~200 LOC)\n- [ ] Step 3: Extract ModelSelectionTab component (lines 400-700) → `src/components/settings/ModelSelectionTab.tsx` (~300 LOC)\n- [ ] Step 4: Extract CustomPromptsTab component (lines 700-1000) → `src/components/settings/CustomPromptsTab.tsx` (~200 LOC)\n- [ ] Step 5: Extract PromptCreatorSettingsTab component (lines 1000-1400) → `src/components/settings/PromptCreatorSettingsTab.tsx` (~400 LOC)\n- [ ] Step 6: Extract CategoriesTab component (lines 1400-1711) → `src/components/settings/CategoriesTab.tsx` (~300 LOC)\n- [ ] Step 7: Refactor main SettingsTab.tsx to orchestrate sub-tabs (~150 LOC remaining)\n- [ ] Step 8: Extract shared utilities → `src/utils/formatting.ts` (formatTimestamp, formatPrice)\n- [ ] Step 9: Extract shared types → `src/types/settingsForm.ts`\n- [ ] Step 10: Update tests to cover each sub-tab independently\n- [ ] Step 11: Verify no regressions with integration tests\n- [ ] Step 12: Update docs/ENGINEERING_STANDARDS.md with new structure\n\n**Acceptance:**\n- **File Size:** All resulting files ≤500 LOC\n- **Complexity:** No function with CC >10\n- **Test Coverage:** Each sub-tab has ≥80% coverage\n- **No Regressions:** All 47 existing test suites pass\n- **Performance:** No degradation in render time (measure with React DevTools Profiler)\n- **Contracts:** Existing `SettingsTabProps` interface unchanged\n\n**Evidence:**\n- Before/after line count comparison table\n- Test coverage report showing individual sub-tab coverage\n- Performance profiling data (render times)\n- Screenshots showing identical UI behavior\n- CI pipeline passing all checks\n\n**Docs Updated:**\n- [ ] README.md - Update project structure section\n- [ ] docs/ENGINEERING_STANDARDS.md - Reference new component structure\n- [ ] Code-map diagram (Mermaid) - Add settings component hierarchy\n- [ ] ADR: Document decision to split SettingsTab and rationale",
      "labels": ["refactor", "tech-debt", "modularity"],
      "assignees": [],
      "milestone": null
    },
    {
      "id": "T2",
      "title": "SUB: Split storage.ts into Domain-Specific Stores (Category: Modularity)",
      "body": "**Why (quantified):**\n- Current file size: 723 lines (target: ≤300 LOC per storage module)\n- Manages 3+ distinct domains: settings, images, batches\n- Complex singleton pattern with multiple responsibilities\n- Difficult to test in isolation\n- Performance bottleneck: debouncing across all storage operations\n- File: `src/lib/storage.ts`\n\n**Baseline:**\n- Lines of Code: 723\n- Domains Mixed: Settings, Image State, Batch Queue\n- Subscription Logic: 156 LOC (can be extracted)\n- Test Files: 8 separate test files (already partially split)\n\n**Plan (small, reversible):**\n- [ ] Step 1: Create `src/lib/storage/` directory\n- [ ] Step 2: Extract SettingsStorage → `src/lib/storage/settingsStorage.ts` (~300 LOC)\n- [ ] Step 3: Extract ImageStateStorage → `src/lib/storage/imageStateStorage.ts` (~200 LOC)\n- [ ] Step 4: Extract BatchStorage → `src/lib/storage/batchStorage.ts` (~150 LOC)\n- [ ] Step 5: Create shared BaseStorage utility → `src/lib/storage/baseStorage.ts` (~100 LOC)\n- [ ] Step 6: Create barrel export → `src/lib/storage/index.ts` (preserve existing API)\n- [ ] Step 7: Update imports across codebase (use codemod/find-replace)\n- [ ] Step 8: Migrate tests to new structure\n- [ ] Step 9: Verify subscription/pub-sub still works across tabs\n- [ ] Step 10: Run full test suite (47 suites must pass)\n\n**Acceptance:**\n- **File Size:** Each storage module ≤300 LOC\n- **Test Coverage:** Each module has ≥80% coverage\n- **No Breaking Changes:** Existing API preserved via barrel export\n- **Performance:** No regression in localStorage read/write times\n- **Cross-Tab Sync:** Storage events still work across tabs\n- **Contracts:** `SettingsStorage.getInstance()` API unchanged\n\n**Evidence:**\n- Before/after file size table\n- Test coverage per module\n- Cross-tab sync demo (video or screenshot)\n- Performance benchmarks (localStorage operation times)\n- CI pipeline passing all checks\n\n**Docs Updated:**\n- [ ] README.md - Update storage architecture section\n- [ ] docs/API_REFERENCE.md - Document new storage module structure\n- [ ] Mermaid diagram showing storage layer architecture\n- [ ] ADR: Document decision to split storage by domain",
      "labels": ["refactor", "tech-debt", "modularity"],
      "assignees": [],
      "milestone": null
    },
    {
      "id": "T3",
      "title": "SUB: Fix Build Failures - Self-Host Fonts (Category: CI)",
      "body": "**Why (quantified):**\n- **Critical blocker:** Production builds fail 100% of the time\n- Error: \"Failed to fetch `Geist` and `Geist Mono` from Google Fonts\"\n- External CDN dependency blocks deployment\n- No offline/airgapped environment support\n- GDPR/privacy concerns with Google Fonts CDN\n- Build time: Currently fails in 5.4s (target: succeed in ≤30s)\n\n**Baseline:**\n- Build Success Rate: 0% (fails every time)\n- Error Location: `[next]/internal/font/google/geist_*.module.css`\n- Font Load Method: Google Fonts CDN (next/font/google)\n- Total Font Weight: Unknown (not measured)\n\n**Plan (small, reversible):**\n- [ ] Step 1: Download Geist and Geist Mono font files from official source\n- [ ] Step 2: Add fonts to `public/fonts/` directory (woff2 format for modern browsers)\n- [ ] Step 3: Create `src/styles/fonts.css` with @font-face declarations\n- [ ] Step 4: Update `src/app/layout.tsx` to import local fonts instead of next/font/google\n- [ ] Step 5: Configure next.config.ts to optimize font loading (preload, font-display: swap)\n- [ ] Step 6: Add font file size check to CI (prevent bloat, target: ≤200KB total)\n- [ ] Step 7: Test build locally: `npm run build`\n- [ ] Step 8: Verify fonts load correctly in dev and prod modes\n- [ ] Step 9: Measure bundle impact (before/after comparison)\n- [ ] Step 10: Update .gitignore if needed (keep font files committed)\n\n**Acceptance:**\n- **Build Success:** `npm run build` completes without errors\n- **Build Time:** ≤30s for production build\n- **Font Loading:** Fonts display correctly in all browsers (Chrome, Firefox, Safari)\n- **Performance:** No increase in First Contentful Paint (FCP) or Largest Contentful Paint (LCP)\n- **Bundle Size:** Font files ≤200KB total\n- **GDPR Compliance:** No external CDN requests\n\n**Evidence:**\n- Successful build output (no errors)\n- Bundle size comparison (before/after)\n- Lighthouse scores (Performance, Accessibility)\n- Screenshots showing correct font rendering\n- CI pipeline green status\n\n**Docs Updated:**\n- [ ] README.md - Document font setup\n- [ ] docs/DEPLOYMENT_SETUP_GUIDE.md - Add font hosting notes\n- [ ] ADR: Document decision to self-host fonts and rationale",
      "labels": ["refactor", "tech-debt", "ci"],
      "assignees": [],
      "milestone": null
    },
    {
      "id": "T4",
      "title": "SUB: Implement Bundle Size Monitoring & Code-Splitting (Category: Performance)",
      "body": "**Why (quantified):**\n- **Current state:** No bundle size tracking (unknown baseline)\n- **Risk:** Bundle can grow unchecked, degrading performance\n- **Target:** First Load JS ≤200KB\n- **Best Practice:** Monitoring prevents performance regressions\n- Large components (SettingsTab: 1,711 LOC) likely bloat bundle\n\n**Baseline:**\n- Bundle Size: Unknown (needs measurement)\n- Code-Splitting: Minimal (only Next.js defaults)\n- Bundle Analyzer: Available but not in CI (`npm run build:analyze`)\n\n**Plan (small, reversible):**\n- [ ] Step 1: Run `npm run build:analyze` to establish baseline\n- [ ] Step 2: Document current First Load JS size\n- [ ] Step 3: Add bundle size check to CI workflow (`.github/workflows/ci.yml`)\n- [ ] Step 4: Configure size budgets in `next.config.ts` (200KB First Load JS, 50KB per page)\n- [ ] Step 5: Implement code-splitting for large tabs (SettingsTab, PromptCreatorTab, ImageToPromptTab)\n- [ ] Step 6: Use dynamic imports: `const SettingsTab = dynamic(() => import('@/components/SettingsTab'))`\n- [ ] Step 7: Add loading states for code-split components\n- [ ] Step 8: Measure bundle size reduction\n- [ ] Step 9: Configure CI to fail if size budget exceeded\n- [ ] Step 10: Document bundle analysis process in runbook\n\n**Acceptance:**\n- **Baseline Established:** First Load JS size documented\n- **CI Check:** Bundle size monitored in every PR\n- **Size Budget:** Build fails if First Load JS >200KB\n- **Code-Splitting:** Top 3 tabs lazy-loaded\n- **Performance:** No increase in Time to Interactive (TTI)\n- **User Experience:** Loading states during code-split transitions\n\n**Evidence:**\n- Bundle analyzer output (before/after)\n- Size budget configuration in next.config.ts\n- CI workflow showing size check step\n- Lighthouse performance scores\n- Screenshots of loading states\n\n**Docs Updated:**\n- [ ] README.md - Add bundle size section\n- [ ] docs/PERFORMANCE_OPTIMIZATION_EXAMPLES.md - Document code-splitting strategy\n- [ ] Runbook - Add bundle size monitoring procedures\n- [ ] ADR: Document size budgets and rationale",
      "labels": ["refactor", "tech-debt", "performance"],
      "assignees": [],
      "milestone": null
    },
    {
      "id": "T5",
      "title": "SUB: Add Golden Signals Observability for Top 5 Paths (Category: Observability)",
      "body": "**Why (quantified):**\n- **Current state:** Zero production observability (blind to issues)\n- **Risk:** Cannot detect/diagnose failures until users report them\n- **MTTR:** Unknown (target: ≤15 min)\n- **Golden Signals:** Latency, Errors, Traffic, Saturation\n\n**Top 5 Critical Paths (by user impact):**\n1. Image upload & prompt generation (ImageToPromptTab)\n2. Batch processing queue (BatchQueue)\n3. Prompt creator form submission (PromptCreatorTab)\n4. Settings API key validation (SettingsTab)\n5. OpenRouter API calls (openrouter.ts)\n\n**Baseline:**\n- **Instrumented Paths:** 0/5\n- **Error Tracking:** None (only console.error)\n- **Performance Monitoring:** None\n- **User Analytics:** None\n\n**Plan (small, reversible):**\n- [ ] Step 1: Choose observability provider (Sentry, LogRocket, or Vercel Analytics)\n- [ ] Step 2: Add provider SDK to dependencies (evaluate bundle impact)\n- [ ] Step 3: Create `src/lib/observability.ts` - centralized instrumentation layer\n- [ ] Step 4: Instrument **Latency** - API call durations (p50, p95, p99)\n- [ ] Step 5: Instrument **Errors** - catch/report all exceptions with context\n- [ ] Step 6: Instrument **Traffic** - track user actions (uploads, generations, saves)\n- [ ] Step 7: Instrument **Saturation** - track queue depth, localStorage usage\n- [ ] Step 8: Add custom spans for OpenRouter API calls\n- [ ] Step 9: Configure alerts for critical thresholds (error rate >1%, p95 >1s)\n- [ ] Step 10: Create dashboard with golden signals\n- [ ] Step 11: Test error reporting with intentional errors\n- [ ] Step 12: Verify no PII in telemetry data\n\n**Acceptance:**\n- **Latency Tracking:** p50/p95/p99 for all 5 critical paths\n- **Error Rate:** All exceptions captured with stack traces\n- **Traffic Monitoring:** User actions tracked (uploads, generations)\n- **Saturation Alerts:** Queue depth >10, localStorage >5MB\n- **Dashboard:** Golden signals visible in real-time\n- **Privacy:** No PII (API keys, user prompts) in telemetry\n- **Performance:** Instrumentation adds <50ms overhead\n\n**Evidence:**\n- Dashboard screenshot showing golden signals\n- Sample error report with stack trace\n- Performance impact benchmark\n- Privacy audit report (no PII)\n- Alert configuration documentation\n\n**Docs Updated:**\n- [ ] docs/QUICK_START.md - Add observability setup\n- [ ] Runbook - Document monitoring and alerting procedures\n- [ ] ADR: Document observability provider choice and rationale\n- [ ] README.md - Add monitoring section",
      "labels": ["refactor", "tech-debt", "observability"],
      "assignees": [],
      "milestone": null
    },
    {
      "id": "T6",
      "title": "SUB: Optimize OpenRouter API - Retry Logic & Circuit Breaker (Category: Performance)",
      "body": "**Why (quantified):**\n- **Current state:** Basic exponential backoff (src/utils/retry.ts)\n- **Gap:** No circuit breaker (can overwhelm failing API)\n- **Risk:** Cascading failures if OpenRouter is degraded\n- **User Impact:** Slow retries block UI (no cancellation)\n- **Cost:** Retries on 5xx errors waste API credits\n- File: `src/lib/openrouter.ts` (451 LOC), `src/utils/retry.ts`\n\n**Baseline:**\n- Retry Strategy: Exponential backoff (3 retries, max 10s)\n- Circuit Breaker: None\n- Request Cancellation: Not implemented\n- Error Classification: Basic (retries all errors)\n- Timeout: 30s per request (no per-model timeout)\n\n**Plan (small, reversible):**\n- [ ] Step 1: Implement circuit breaker pattern in `src/lib/circuitBreaker.ts`\n- [ ] Step 2: Add request cancellation using AbortController\n- [ ] Step 3: Classify errors: retriable (429, 503) vs non-retriable (400, 401)\n- [ ] Step 4: Add per-model timeout configuration (fast models: 10s, slow: 60s)\n- [ ] Step 5: Implement request deduplication (prevent double-submit)\n- [ ] Step 6: Add retry budget (max 10 retries/min per model)\n- [ ] Step 7: Emit metrics for retry rate, circuit breaker state\n- [ ] Step 8: Add UI feedback for retry attempts (progress indicator)\n- [ ] Step 9: Test with simulated API failures\n- [ ] Step 10: Document retry behavior in user-facing docs\n\n**Acceptance:**\n- **Circuit Breaker:** Opens after 5 consecutive failures, half-open after 30s\n- **Error Classification:** 4xx errors not retried (except 429)\n- **Cancellation:** User can cancel in-flight requests\n- **Timeouts:** Configurable per model (10s-60s)\n- **Retry Budget:** Max 10 retries/min per model\n- **User Feedback:** Progress indicator shows retry attempts\n- **No Regressions:** Existing API calls still work\n\n**Evidence:**\n- Circuit breaker state machine diagram\n- Test results with simulated failures\n- Retry metrics dashboard\n- UI screenshots showing retry feedback\n- Performance benchmarks (latency reduction)\n\n**Docs Updated:**\n- [ ] docs/API_REFERENCE.md - Document retry behavior\n- [ ] Runbook - Add circuit breaker monitoring\n- [ ] ADR: Document retry strategy and circuit breaker design\n- [ ] README.md - Update API integration section",
      "labels": ["refactor", "tech-debt", "performance"],
      "assignees": [],
      "milestone": null
    },
    {
      "id": "T7",
      "title": "SUB: Refactor PromptCreatorTab.tsx into Focused Components (Category: Modularity)",
      "body": "**Why (quantified):**\n- Current file size: 974 lines (target: ≤500 LOC)\n- Long render functions (185 lines)\n- Mixes concerns: UI, state, API, storage\n- Has ESLint disable comment for max-file-size\n- File: `src/components/PromptCreatorTab.tsx`\n\n**Baseline:**\n- Lines of Code: 974\n- Longest Function: 185 lines (render method)\n- Cyclomatic Complexity: ~25\n- Test Coverage: Partial\n\n**Plan (small, reversible):**\n- [ ] Step 1: Extract PromptCreatorForm component (~250 LOC)\n- [ ] Step 2: Extract PromptCreatorResults component (~200 LOC)\n- [ ] Step 3: Extract PromptCreatorBatchConfig component (~150 LOC)\n- [ ] Step 4: Extract PromptCreatorHistory component (~200 LOC)\n- [ ] Step 5: Create custom hook: `usePromptCreatorState` (~100 LOC)\n- [ ] Step 6: Refactor main PromptCreatorTab to orchestrate (~150 LOC)\n- [ ] Step 7: Update tests for new components\n- [ ] Step 8: Remove ESLint disable comment\n\n**Acceptance:**\n- **File Size:** All files ≤500 LOC\n- **Complexity:** No function >50 lines or CC >10\n- **Test Coverage:** ≥80% per component\n- **No Regressions:** All existing tests pass\n- **Contracts:** PromptCreatorTabProps unchanged\n\n**Evidence:**\n- Before/after line count table\n- Test coverage report\n- CI passing all checks\n\n**Docs Updated:**\n- [ ] README.md - Update component structure\n- [ ] Mermaid diagram - PromptCreator component hierarchy\n- [ ] ADR: Document refactoring approach",
      "labels": ["refactor", "tech-debt", "modularity"],
      "assignees": [],
      "milestone": null
    },
    {
      "id": "T8",
      "title": "SUB: Extract Shared Form Utilities & Validation (Category: Modularity)",
      "body": "**Why (quantified):**\n- **Duplication:** Form validation repeated across 3+ components\n- **Inconsistency:** Different validation logic for similar inputs\n- **Testability:** Validation logic embedded in components\n- **Files affected:** SettingsTab.tsx, PromptCreatorTab.tsx, BestPracticesTab.tsx\n\n**Baseline:**\n- Duplicated Validation: ~150 LOC total\n- Duplicated Formatters: formatPrice, formatTimestamp repeated\n- Duplicated ID Generators: createPromptCreatorId, createBestPracticeId\n\n**Plan (small, reversible):**\n- [ ] Step 1: Create `src/utils/formatting.ts` - formatPrice, formatTimestamp\n- [ ] Step 2: Create `src/utils/idGenerator.ts` - unified ID generation\n- [ ] Step 3: Create `src/utils/validation.ts` - form validators\n- [ ] Step 4: Create `src/hooks/useFormValidation.ts` - reusable validation hook\n- [ ] Step 5: Replace duplicated code across components\n- [ ] Step 6: Add comprehensive tests for utilities\n- [ ] Step 7: Update existing tests to use new utilities\n\n**Acceptance:**\n- **Duplication Reduction:** ≤5% code duplication\n- **Test Coverage:** Utilities have 100% coverage\n- **No Regressions:** All form validations work as before\n- **Consistency:** Same validation rules across components\n\n**Evidence:**\n- Code duplication report (before/after)\n- Test coverage report for utilities\n- CI passing all checks\n\n**Docs Updated:**\n- [ ] docs/API_REFERENCE.md - Document utility functions\n- [ ] ADR: Document utility extraction strategy",
      "labels": ["refactor", "tech-debt", "modularity"],
      "assignees": [],
      "milestone": null
    },
    {
      "id": "T9",
      "title": "SUB: Enhance CI Pipeline - Parallel Jobs & Caching (Category: CI)",
      "body": "**Why (quantified):**\n- **Current CI time:** 25.7s (already fast, but can be improved)\n- **Sequential jobs:** Test, security, coverage run in parallel (good!)\n- **Cache hit rate:** Unknown\n- **Opportunity:** Pre-build type checking, better caching\n\n**Baseline:**\n- Total CI Time: 25.7s\n- Test Time: 7.5s\n- Lint Time: ~5s\n- Typecheck Time: ~10s\n- Cache Hit Rate: Unknown\n\n**Plan (small, reversible):**\n- [ ] Step 1: Add cache metrics to CI logs\n- [ ] Step 2: Optimize npm cache (use npm ci with better cache keys)\n- [ ] Step 3: Cache TypeScript build info (.tsbuildinfo)\n- [ ] Step 4: Cache ESLint cache (.eslintcache)\n- [ ] Step 5: Add pr-check job that runs only changed files\n- [ ] Step 6: Parallelize lint and typecheck (currently sequential)\n- [ ] Step 7: Add early exit for docs-only changes\n- [ ] Step 8: Measure CI time improvement\n\n**Acceptance:**\n- **CI Time:** Maintain ≤30s (or improve)\n- **Cache Hit Rate:** ≥80% for dependency installs\n- **Parallel Jobs:** Lint and typecheck run simultaneously\n- **Early Exit:** Docs-only changes skip code checks\n\n**Evidence:**\n- CI time comparison (before/after)\n- Cache hit rate metrics\n- Job duration breakdown\n\n**Docs Updated:**\n- [ ] docs/ENGINEERING_STANDARDS.md - Document CI optimizations\n- [ ] .github/workflows/ci.yml - Add comments explaining cache strategy",
      "labels": ["refactor", "tech-debt", "ci"],
      "assignees": [],
      "milestone": null
    },
    {
      "id": "T10",
      "title": "SUB: Add E2E Tests for Critical User Journeys (Category: CI)",
      "body": "**Why (quantified):**\n- **Current state:** 47 unit/integration tests (393 test cases)\n- **Gap:** No end-to-end tests for user flows\n- **Risk:** Integration issues not caught until production\n- **Coverage:** Unit tests at ≥60%, but no E2E coverage\n\n**Critical User Journeys:**\n1. Upload image → Generate prompt → Save result\n2. Create prompt → Generate batch → Rate results\n3. Configure API key → Validate → Select models\n4. Add best practice → Assign to category → Search\n5. View usage history → Filter by date → Export\n\n**Baseline:**\n- E2E Tests: 0\n- E2E Framework: None\n- CI E2E Time: N/A\n\n**Plan (small, reversible):**\n- [ ] Step 1: Evaluate E2E frameworks (Playwright vs Cypress)\n- [ ] Step 2: Install chosen framework (prefer Playwright for Next.js)\n- [ ] Step 3: Create `tests/e2e/` directory\n- [ ] Step 4: Write E2E test for Journey 1 (image upload flow)\n- [ ] Step 5: Write E2E test for Journey 2 (prompt creator flow)\n- [ ] Step 6: Write E2E test for Journey 3 (settings flow)\n- [ ] Step 7: Add E2E tests to CI (run on main branch only)\n- [ ] Step 8: Configure visual regression testing (optional)\n- [ ] Step 9: Document E2E test patterns\n\n**Acceptance:**\n- **E2E Coverage:** All 5 critical journeys tested\n- **CI Integration:** E2E tests run on every main branch commit\n- **Test Time:** E2E suite completes in ≤2 min\n- **Reliability:** Zero flaky E2E tests\n- **Documentation:** E2E testing guide created\n\n**Evidence:**\n- E2E test execution videos\n- CI logs showing E2E test runs\n- Coverage report including E2E scenarios\n\n**Docs Updated:**\n- [ ] docs/ENGINEERING_STANDARDS.md - Add E2E testing section\n- [ ] README.md - Document how to run E2E tests\n- [ ] ADR: Document E2E framework choice",
      "labels": ["refactor", "tech-debt", "ci"],
      "assignees": [],
      "milestone": null
    },
    {
      "id": "T11",
      "title": "SUB: Update Architecture Diagrams & Component Map (Category: Docs)",
      "body": "**Why (quantified):**\n- **Current state:** Outdated or missing architecture diagrams\n- **Pain point:** New developers take 2-3 days to onboard\n- **Gap:** No visual component hierarchy\n- **Documentation debt:** Diagrams don't reflect recent refactoring\n\n**Baseline:**\n- Architecture Diagrams: Outdated (pre-refactoring)\n- Component Map: None\n- Onboarding Time: 2-3 days for new developers\n- Docs Coverage: README has basic structure, no diagrams\n\n**Plan (small, reversible):**\n- [ ] Step 1: Create component hierarchy diagram (Mermaid)\n- [ ] Step 2: Create data flow diagram (Mermaid)\n- [ ] Step 3: Create storage architecture diagram (Mermaid)\n- [ ] Step 4: Create CI/CD pipeline diagram (Mermaid)\n- [ ] Step 5: Update README.md with all diagrams\n- [ ] Step 6: Create docs/ARCHITECTURE.md with detailed explanations\n- [ ] Step 7: Add diagram source files to docs/diagrams/\n- [ ] Step 8: Verify diagrams render correctly on GitHub\n\n**Acceptance:**\n- **Diagrams Created:** 4 architecture diagrams (component, data flow, storage, CI/CD)\n- **Format:** Mermaid (renders natively on GitHub)\n- **Accuracy:** Reflects current codebase structure\n- **Clarity:** New developers can understand architecture in <1 hour\n- **Maintenance:** Diagrams stored as code (Mermaid source)\n\n**Evidence:**\n- Screenshots of rendered diagrams\n- Developer feedback on clarity\n- Onboarding time improvement\n\n**Docs Updated:**\n- [ ] README.md - Embed architecture diagrams\n- [ ] docs/ARCHITECTURE.md - Create new document\n- [ ] docs/diagrams/ - Add Mermaid source files",
      "labels": ["refactor", "tech-debt", "docs"],
      "assignees": [],
      "milestone": null
    },
    {
      "id": "T12",
      "title": "SUB: Create Runbook for Production Monitoring (Category: Docs)",
      "body": "**Why (quantified):**\n- **Current state:** No runbook for production issues\n- **Risk:** High MTTR (mean time to resolution)\n- **Gap:** No documented SLOs, alerts, or incident response\n- **Dependency:** Requires #T5 (observability) to be complete\n\n**Baseline:**\n- Runbook: Does not exist\n- SLOs: Not defined\n- Alerts: Not configured\n- Incident Response: Ad-hoc\n- MTTR: Unknown (target: ≤15 min)\n\n**Plan (small, reversible):**\n- [ ] Step 1: Define SLOs (Service Level Objectives)\n  - Availability: 99.9% uptime\n  - Latency: p95 ≤800ms\n  - Error Rate: ≤0.5%\n- [ ] Step 2: Document alert thresholds\n- [ ] Step 3: Create incident response playbook\n- [ ] Step 4: Document common issues and resolutions\n- [ ] Step 5: Add troubleshooting decision tree\n- [ ] Step 6: Document rollback procedures\n- [ ] Step 7: Create on-call rotation guide\n- [ ] Step 8: Add monitoring dashboard links\n\n**Acceptance:**\n- **SLOs Defined:** Clear targets for availability, latency, errors\n- **Alerts Documented:** Thresholds and escalation paths\n- **Playbook Created:** Step-by-step incident response\n- **Common Issues:** Top 10 issues with resolutions\n- **Rollback Procedures:** Clear steps to revert deployments\n\n**Evidence:**\n- Runbook document (docs/RUNBOOK.md)\n- SLO dashboard\n- Sample incident walk-through\n\n**Docs Updated:**\n- [ ] docs/RUNBOOK.md - Create new document\n- [ ] README.md - Link to runbook\n- [ ] docs/README.md - Add runbook to index",
      "labels": ["refactor", "tech-debt", "docs"],
      "assignees": [],
      "milestone": null
    }
  ]
}
